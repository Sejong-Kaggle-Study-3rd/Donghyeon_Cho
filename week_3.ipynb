{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "week_3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP4vbgRkf5Q7Jv+7RLeimAq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hyeon9698/Donghyeon_Cho/blob/main/week_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8zrbPikx9Bi"
      },
      "source": [
        "# week 3\n",
        "KNN\n",
        "### 분류와 회귀\n",
        "- 분류\n",
        "    - 분류는 미리 정의된, 가능성 있는 여러 클래스 레이블 중 하나를 예측하는 것\n",
        "    - 두 개로만 나누는 이진 분류(binary classification)와 셋 이상의 클래스로 분류하는 다중 분류(multiclass classification)으로 나뉨\n",
        "    - 분류 예시: 얼굴 인식, 숫자 판별 (MNIST) 등\n",
        "- 회귀\n",
        "    - 연속적인 숫자 또는 부동소수점수 (실수)를 예측하는 것\n",
        "    - 회귀 예시: 주식 가격을 예측하여 수익을 내는 알고리즘 등\n",
        "\n",
        "### KNN의 개념\n",
        "- KNN이란?\n",
        "    - 주변 k 개의 자료의 클래스 중 가장 많은 클래스로 특정 자료를 분류하는 방식\n",
        "    - 새로운 자료를 가장 가까운 자료 5개의 자료를 이용하여 투표가 가장 많은 클래스로 할당\n",
        "    - Training-data 자체가 모형일 뿐 어떠한 추정 방법도 모형도 없음\n",
        "        - 즉, 데이터의 분포를 표현하기 위한 파라미터를 추정하지 않음\n",
        "    - 매우 간단한 방법이지만 performance는 떨어지지 않음\n",
        "    - 게으른 학습(lazy learner) 또는 사례중심학습(instance-based learning)\n",
        "        - 게으른 학습이란: 알고리즘은 훈련 데이터에서 판별 함수(discriminative function)을 학습하는 대신 훈련 데이터 셋을 메모리에 저장하기 방법\n",
        "    - 데이터의 차원이 증가하면 차원의 저주(curse of dimension) 문제가 발생함\n",
        "        - 즉, KNN은 차원이 증가할 수록 성능 저하가 심함\n",
        "            - 데이터의 차원(dimensionality)이 증가할수록 해당 공간의 크기(부피)가 기하급수적으로 증가하여 동일한 개수의 데이터의 밀도는 차원이 증가할수록 급속도로 희박(sparse)해짐\n",
        "            - 차원이 증가할수록 데이터의 분포 분석에 필요한 샘플 데이터의 개수가 기하급수적으로 증가하게 되는데 이러한 어려움을 표현한 용어가 차원의 저주임\n",
        "    - i번째 관측치와 j번째 관측치의 거리로 Minkowski 거리를 이용\n",
        "\n",
        "    ![image](https://user-images.githubusercontent.com/41141851/112100719-e83e4280-8be8-11eb-8347-74d4e2e7cc73.png)\n",
        "\n",
        "### KNN의 하이퍼파라미터\n",
        "- 탐색할 이웃 수(k)와 거리 측정 방법\n",
        "    - k가 작을 경우 데이터의 지역적 특성을 지나치게 반영하여 과접합(overfitting) 발생\n",
        "    - 반대로 매우 클 경우 모델이 과하게 정규화 (underfitting) 발생"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D1r5l1QUx_31"
      },
      "source": [
        ""
      ]
    }
  ]
}